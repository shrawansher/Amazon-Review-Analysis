{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shraws/anaconda3/lib/python3.6/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['hstack', 'random', 'clf']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n",
      "/Users/shraws/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%pylab inline \n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "import progressbar\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_curve, roc_auc_score, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Ridge, BayesianRidge, LinearRegression\n",
    "from sklearn import cross_validation\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, Normalizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from collections import Counter, OrderedDict\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import PorterStemmer\n",
    "from nltk import word_tokenize\n",
    "\n",
    "from scipy.sparse import hstack\n",
    "from afinn import Afinn\n",
    "\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedLineDocument\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "from gensim import models\n",
    "\n",
    "import time\n",
    "import afinn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "REVIEWS = 'reviews'\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "category_map = {\n",
    "   # \"Amazon_Instant_Video\" : 0,\n",
    "   # \"Apps_for_Android\" : 1,\n",
    "   # \"Automotive\" : 2,\n",
    "    \"Baby\" : 3,\n",
    "   # \"Beauty\" : 4,\n",
    "   # \"Books\" : 5,\n",
    "#     \"CDs_and_Vinyl\" : 6,\n",
    "#     \"Cell_Phones_and_Accessories\" : 7,\n",
    "     \"Clothing_Shoes_and_Jewelry\" : 8,\n",
    "#     \"Digital_Music\" : 9,\n",
    "  #    \"Electronics\" : 10\n",
    "     \"Grocery_and_Gourmet_Food\" : 11\n",
    "#     \"Health_and_Personal_Care\" : 12,\n",
    "#     \"Home_and_Kitchen\" : 13,\n",
    "#     \"Kindle_Store\" : 14,\n",
    "#     \"Movies_and_TV\" : 15,\n",
    "   #  \"Musical_Instruments\" : 16,\n",
    "   #  \"Office_Products\" : 17\n",
    "#     \"Patio_Lawn_and_Garden\" : 18,\n",
    "#     \"Pet_Supplies\" : 19,\n",
    "#     \"Sports_and_Outdoors\" : 20,\n",
    "#     \"Tools_and_Home_Improvement\" : 21,\n",
    "#     \"Toys_and_Games\" : 22,\n",
    "#     \"Video_Games\" : 23\n",
    "}\n",
    "\n",
    "col_names = [\"reviewer_id\", \"asin\", \"summary\",\"review_text\", \"overall\", \"category\", \"total_votes\",\"upvotes\",\"score\",\n",
    "             \"good\", \"bad\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_dataset(category_t):\n",
    "    data =[]\n",
    "    for category in category_map:\n",
    "        if category_map[category] == category_t:\n",
    "            fn = \"data/\" + REVIEWS+ \"_\" + category + \"_\"+\"5\" + \".json\"\n",
    "            print(\"Reading category\", category)\n",
    "            with open(fn) as f:\n",
    "                for line in f:\n",
    "                    d = json.loads(line)\n",
    "                    pf, tf = d[\"helpful\"]\n",
    "                    if tf >1 and len(d[\"reviewText\"].split())  >10:\n",
    "                        score = int(pf) / int(tf)\n",
    "                        row = [d[\"reviewerID\"], \n",
    "                               d[\"asin\"], \n",
    "                               d[\"summary\"],\n",
    "                               d[\"reviewText\"],\n",
    "                               d[\"overall\"],\n",
    "                               category_map[category],\n",
    "                               int(tf),\n",
    "                               int(pf),\n",
    "                               (score),\n",
    "                               int(score >= 0.80),\n",
    "                               int(score <= 0.20)]\n",
    "                        data.append(row)\n",
    "    print(\"File read!\")\n",
    "    return pd.DataFrame(data, columns=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Calculates fraction of unique words\n",
    "def text_richness(text):\n",
    "    return len(set(text.split()))/len(text.split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_text(text, stem_in = True):\n",
    "    # lowercase\n",
    "    # remove symbols\n",
    "    RE_PREPROCESS = r'\\W+|\\d+'  \n",
    "#get rid of punctuation and make everything lowercase\n",
    "    text = re.sub(RE_PREPROCESS, ' ', text).lower()\n",
    "    if stem_in:\n",
    "        return stemmer.stem(text)\n",
    "    return text\n",
    "\n",
    "def total_characters(fd):\n",
    "    sum = 0\n",
    "    for v,k in fd.items():\n",
    "        sum += (v*k)\n",
    "    return sum\n",
    "\n",
    "def word_length_avg(text):\n",
    "    fd = nltk.FreqDist(len(w) for w in process_text(text).split())\n",
    "    print(fd)\n",
    "    if fd.N() ==0:\n",
    "        print(\"issue detected: \", text)\n",
    "    return total_characters(fd)/fd.N()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_topics(tfidf, features, N_TOPICS=3, N_TOP_WORDS=5,):\n",
    "    \"\"\"\n",
    "    Given a matrix of features of text data generate topics\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    tfidf: scipy sparse matrix\n",
    "        sparse matrix of text features\n",
    "    N_TOPICS: int\n",
    "        number of topics (default 10)\n",
    "    N_TOP_WORDS: int\n",
    "        number of top words to display in each topic (default 10)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    ls_keywords: ls\n",
    "        list of keywords for each topics\n",
    "    doctopic: array\n",
    "        numpy array with percentages of topic that fit each category\n",
    "    N_TOPICS: int\n",
    "        number of assumed topics\n",
    "    N_TOP_WORDS: int\n",
    "        Number of top words in a given topic. \n",
    "    \"\"\"\n",
    "    \n",
    "    with progressbar.ProgressBar(max_value=progressbar.UnknownLength) as bar:\n",
    "        i=0\n",
    "        lda = LatentDirichletAllocation( n_topics= N_TOPICS,\n",
    "                                       learning_method='online') #create an object that will create 5 topics\n",
    "        bar.update(i)\n",
    "        i+=1\n",
    "        doctopic = lda.fit_transform( tfidf )\n",
    "        bar.update(i)\n",
    "        i+=1\n",
    "        \n",
    "        ls_keywords = []\n",
    "        for i,topic in enumerate(lda.components_):\n",
    "            word_idx = np.argsort(topic)[::-1][:N_TOP_WORDS]\n",
    "            keywords = ', '.join( features[i] for i in word_idx)\n",
    "            ls_keywords.append(keywords)\n",
    "            print(i, keywords)\n",
    "            bar.update(i)\n",
    "            i+=1\n",
    "            \n",
    "    return ls_keywords, doctopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_bag_of_words(corpus,\n",
    "                       NGRAM_RANGE=(0,1),\n",
    "                       stop_words = None,\n",
    "                       stem = False,\n",
    "                       MIN_DF = 0.02,\n",
    "                       MAX_DF = 0.8,\n",
    "                       USE_IDF=False):\n",
    "    \"\"\"\n",
    "    Turn a corpus of text into a bag-of-words.\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    corpus: ls\n",
    "        test of documents in corpus    \n",
    "    NGRAM_RANGE: tupule\n",
    "        range of N-gram default (0,1)\n",
    "    stop_words: ls\n",
    "        list of commonly occuring words that have little semantic\n",
    "        value\n",
    "    stem: bool\n",
    "        use a stemmer to stem words\n",
    "    MIN_DF: float\n",
    "       exclude words that have a frequency less than the threshold\n",
    "    MAX_DF: float\n",
    "        exclude words that have a frequency greater than the threshold\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    bag_of_words: scipy sparse matrix\n",
    "        scipy sparse matrix of text\n",
    "    features:\n",
    "        ls of words\n",
    "    \"\"\"\n",
    "    #parameters for vectorizer \n",
    "    ANALYZER = \"word\" #unit of features are single words rather then phrases of words \n",
    "    STRIP_ACCENTS = 'unicode'\n",
    "     \n",
    "    if stem:\n",
    "        tokenize = lambda x: [stemmer.stem(i) for i in x.split()]\n",
    "    else:\n",
    "        tokenize = None\n",
    "    vectorizer = CountVectorizer(analyzer=ANALYZER,\n",
    "                                tokenizer=tokenize, \n",
    "                                ngram_range=NGRAM_RANGE,\n",
    "                                stop_words = stop_words,\n",
    "                                strip_accents=STRIP_ACCENTS,\n",
    "                                min_df = MIN_DF,\n",
    "                                max_df = MAX_DF)\n",
    "    \n",
    "    bag_of_words = vectorizer.fit_transform( corpus ) #transform our corpus is a bag of words \n",
    "    features = vectorizer.get_feature_names()\n",
    "\n",
    "    if USE_IDF:\n",
    "        NORM = None #turn on normalization flag\n",
    "        SMOOTH_IDF = True #prvents division by zero errors\n",
    "        SUBLINEAR_IDF = True #replace TF with 1 + log(TF)\n",
    "        transformer = TfidfTransformer(norm = NORM,smooth_idf = SMOOTH_IDF,sublinear_tf = True)\n",
    "        #get the bag-of-words from the vectorizer and\n",
    "        #then use TFIDF to limit the tokens found throughout the text \n",
    "        tfidf = transformer.fit_transform(bag_of_words)\n",
    "        \n",
    "        return tfidf, features\n",
    "    else:\n",
    "        return bag_of_words, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_word_counts(bag_of_words, feature_names):\n",
    "    \"\"\"\n",
    "    Get the ordered word counts from a bag_of_words\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    bag_of_words: obj\n",
    "        scipy sparse matrix from CounterVectorizer\n",
    "    feature_names: ls\n",
    "        list of words\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    word_counts: dict\n",
    "        Dictionary of word counts\n",
    "    \"\"\"\n",
    "    np_bag_of_words = bag_of_words.toarray()\n",
    "    word_count = np.sum(np_bag_of_words,axis=0)\n",
    "    np_word_count = np.asarray(word_count).ravel()\n",
    "    dict_word_counts = dict( zip(feature_names, np_word_count) )\n",
    "    \n",
    "    orddict_word_counts = OrderedDict( \n",
    "                                    sorted(dict_word_counts.items(), key=lambda x: x[1], reverse=True), )\n",
    "    \n",
    "    return orddict_word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf_names = [\"Ridge\",\n",
    "             \"BayesianRidge\",\n",
    "             \"LinearRegression\"\n",
    "            ]\n",
    "classifiers = [Ridge(),\n",
    "               BayesianRidge(),\n",
    "               LinearRegression()\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cats = [3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading category Baby\n",
      "number of revs 32955\n",
      "text richness score calculated\n",
      "sentiment score calculated\n",
      "Median score 0.75\n",
      "Mean score 0.7244013536627132\n",
      "Length of training data 26364\n",
      "Length of test data 6591\n",
      "Logistic Accuracy 0.896373843119\n",
      "\n",
      "Random Forest Accuracy 0.896373843119\n",
      "\n",
      "Baseline accuracy for test data 0.7217562327139867\n",
      "baseline mse 0.0735467040926\n",
      "mse 0.00803197100825\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for cat in cats:\n",
    "    df = read_dataset(cat)\n",
    "    df.head()\n",
    "    print(\"number of revs\",len(df))\n",
    "\n",
    "    df['review_length'] = [len(x.split()) for x in df['review_text']]\n",
    "\n",
    "    df['text_richness'] = df.review_text.apply(lambda x: text_richness(x))\n",
    "    print(\"text richness score calculated\")\n",
    "\n",
    "    afinn  = Afinn(emoticons=True)\n",
    "    df['afinn'] = df.review_text.apply(lambda x: afinn.score(x))\n",
    "    sentiment_mean = np.mean(df['afinn'])\n",
    "    sentiment_std = np.std(df['afinn'])\n",
    "    df['afinn_normal'] = (df['afinn']-sentiment_mean)/sentiment_std\n",
    "    print(\"sentiment score calculated\")\n",
    "    \n",
    "    image_regex = 'picture[s]?|attach[ed|ment]|image[s]?|video[s]'\n",
    "    df['image_flag'] = [1 if x else 0 for x in df.review_text.str.contains(image_regex, regex=True, case=0)]\n",
    "\n",
    "#     df['avg_word_len'] = df.review_text.apply(lambda x: word_length_avg(x))\n",
    "\n",
    "    score_median = np.median(df['score'])\n",
    "    print(\"Median score\", score_median)\n",
    "\n",
    "    score_mean = np.mean(df['score'])\n",
    "    print(\"Mean score\", score_mean)\n",
    "\n",
    "#     df_good = df[df['score']>=0.5]\n",
    "#     df_bad = df[df['score']<0.5]\n",
    "\n",
    "#     len_bad = len(df_bad)\n",
    "#     len_good = len(df_good)\n",
    "\n",
    "#     print(\"Not Helpful reviews\",len_bad)\n",
    "#     print(\"Helpful reviews\", len_good)\n",
    "#     print(\"Baseline accuracy\",len_good/len(df))\n",
    "\n",
    "    corpus = df[\"review_text\"]\n",
    "\n",
    "    #Stop word list\n",
    "    eng_stopwords =  stopwords.words('english')\n",
    "\n",
    "    #get rid of the punctuations and set all characters to lowercase\n",
    "    RE_PREPROCESS = r'\\W+|\\d+' #the regular expressions that matches all non-characters\n",
    "    stemmer = PorterStemmer()\n",
    "    #Retrieve words and lowercase them\n",
    "    processed_corpus = np.array( [ re.sub(RE_PREPROCESS, ' ', comment).lower() for comment in corpus] )\n",
    "\n",
    "    processed_bag_of_words, processed_features = create_bag_of_words(processed_corpus,\n",
    "                                                                     stop_words=eng_stopwords,\n",
    "                                                                     stem=True,\n",
    "                                                                     NGRAM_RANGE=(0,2),\n",
    "                                                                     USE_IDF = True)\n",
    "\n",
    "    y= []\n",
    "    for score in df['score']:\n",
    "        if score >= 0.5:\n",
    "            y.append(1)\n",
    "        else:\n",
    "            y.append(0)\n",
    "    \n",
    "    y_reg = df['score']\n",
    "    \n",
    "\n",
    "    #Adding features\n",
    "    X = hstack((processed_bag_of_words,np.array(df['overall']/5)[:,None]))\n",
    "    X = hstack((X,np.array(df['review_length']/np.max(df['review_length']))[:,None]))\n",
    "    X = hstack((X,np.array(df['image_flag'])[:,None]))\n",
    "    X = hstack((X,np.array(df['afinn_normal'])[:,None]))\n",
    "    #Logistic\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2, random_state=42)\n",
    "\n",
    "    print(\"Length of training data\",len(y_train))\n",
    "    print(\"Length of test data\", len(y_test))\n",
    "\n",
    "\n",
    "    clf = LogisticRegression(penalty='l1',C=0.02)\n",
    "    mdl = clf.fit(X_train, y_train) #train the classifer to get the model\n",
    "    y_score = mdl.predict_proba(X_test )\n",
    "    y_pred = mdl.predict(X_test)\n",
    "    acc1= accuracy_score(y_test, y_pred, normalize=True, sample_weight=None)\n",
    "    print(\"Logistic Accuracy\", acc1)\n",
    "    print()\n",
    "    clf = RandomForestClassifier(n_jobs=2, random_state=0)\n",
    "    # Train the Classifier to take the training features and learn how they relate\n",
    "    # to the training y (the species)\n",
    "    mdl = clf.fit(X_train, y_train)\n",
    "    y_score = mdl.predict_proba(X_test )\n",
    "    y_pred = mdl.predict(X_test)\n",
    "    acc2= accuracy_score(y_test, y_pred, normalize=True, sample_weight=None)\n",
    "    print(\"Random Forest Accuracy\", acc1)\n",
    "    print()\n",
    "    \n",
    "    #regresssion\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y_reg,test_size=0.2, random_state=42)\n",
    "    baseline_score = np.mean(y_test)\n",
    "    print(\"Baseline accuracy for test data\", baseline_score)\n",
    "    \n",
    "    reg = linear_model.LinearRegression()\n",
    "    mdl = reg.fit(X_train, y_train)\n",
    "    y_score= mdl.predict(X_test)\n",
    "    \n",
    "    print(\"baseline mse\",mean_squared_error(y_test, [baseline_score]*len(y_test)))\n",
    "    \n",
    "    print(\"mse\", mean_squared_error(y_score, [baseline_score]*len(y_test)))\n",
    "    print(\"\\n\\n\")\n",
    "#     for i in range(len(y_test)):\n",
    "#         if math.fabs(y_test[i]-y_score) <0.02 and y_score<0.5:\n",
    "#             print()\n",
    "#     print('Accuracy of different classifier, with Normalization')\n",
    "#     normalization_methods_name = ['StandardScaler', 'Normalizer']#, 'RobustScaler'\n",
    "#     normalization_methods = [StandardScaler(), Normalizer()]#, RobustScaler(),\n",
    "#     # iterate over classifiers\n",
    "#     for name, clf in zip(clf_names, classifiers):\n",
    "#         print('\\n')\n",
    "#         for norm_name, norm in zip(normalization_methods_name, normalization_methods):\n",
    "#             loo = cross_validation.KFold(5)\n",
    "#             scores = cross_validation.cross_val_score(make_pipeline(clf), X, y_reg, scoring='neg_mean_squared_error', cv=loo)\n",
    "#             clf.fit(X,y_reg)\n",
    "#             print('{},{},mean_squared_error:{}'.format(name, norm_name,mean_squared_error(y_reg, clf.predict(X))))\n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "y_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.fabs(9-99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ff = pd.DataFrame(columns=['s','f'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s</th>\n",
       "      <th>f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [s, f]\n",
       "Index: []"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s</th>\n",
       "      <th>f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   s  f\n",
       "0  2  3\n",
       "2  2  3\n",
       "1  2  3"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff.iloc[0] = [2,3]\n",
    "ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
